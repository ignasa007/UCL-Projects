{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Helper functions for plotting the confusion matrix and annotating it\n",
    "from plots import heatmap, annotate_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(fn):\n",
    "    \n",
    "    '''\n",
    "    Read the data file with rows formatted as {label, features},\n",
    "    each corresponding to a data point.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fn: string\n",
    "        name of the file to read\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    inputs: np.ndarray\n",
    "        array of shape (N, D) with pixel values laid out in rows\n",
    "    labels: np.ndarray\n",
    "        array of shape (N,) with labels of the data points\n",
    "    '''\n",
    "\n",
    "    data = np.loadtxt(fn)\n",
    "    inputs, labels = data[:, 1:], data[:, 0]\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "X, Y = import_data('zipcombo.dat')\n",
    "N_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseKernel:\n",
    "\n",
    "    '''\n",
    "    Define basic operations used by implementations of the polynomial \n",
    "    and the Gaussian kernels.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    base_kernel_matrix: np.ndarray\n",
    "        array of shape (N, M) where N is the number of samples in the \n",
    "        first dataset (eg. test) and M is for the second (eg. train)\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    base_kernel(X1, X2):\n",
    "        evaluate the Gram matrix between X1 and X2 using the base kernel\n",
    "    indices(row_indices, col_indices):\n",
    "        process the requested indices for calculating the Gram matrix to\n",
    "        avoid runtime errors\n",
    "    kernel(hparam, row_indices, col_indices):\n",
    "        calculate the Gram matrix for the requested pairs of data points\n",
    "        using the specified hyper-parameter\n",
    "    '''\n",
    "\n",
    "    def __init__(self, X1, X2=None):\n",
    "        self.base_kernel_matrix = self.base_kernel(X1, X2 if X2 is not None else X1)\n",
    "\n",
    "    def base_kernel(self, X1, X2):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def indices(self, row_indices, col_indices):\n",
    "\n",
    "        '''\n",
    "        Check the indices requested from {X1} and {X2} respectively, and\n",
    "        format them to be a valid index for the {base_kernel_matrix}\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        row_indices: np.ndarray\n",
    "            sequence of N indices requested from {X1}\n",
    "        col_indices: np.ndarray\n",
    "            sequence of M indices requested from {X2}\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        indices: np.ndarray\n",
    "            2 arrays with 2 dimensions each, which together form an open mesh\n",
    "        '''\n",
    "        \n",
    "        # if row_indices is None, return all rows\n",
    "        if row_indices is None:\n",
    "            row_indices = np.arange(self.base_kernel_matrix.shape[0])\n",
    "        # if col_indices is None, return all columns\n",
    "        if col_indices is None:\n",
    "            col_indices = np.arange(self.base_kernel_matrix.shape[1])\n",
    "            \n",
    "        return np.ix_(row_indices, col_indices)\n",
    "    \n",
    "    def kernel(self, hparam, row_indices=None, col_indices=None):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialKernel(BaseKernel):\n",
    "\n",
    "    '''\n",
    "    Compute the polynomial kernel by first precomputing the pairwise \n",
    "    inner products, and then raising them to the degree, {d}.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    base_kernel_matrix: np.ndarray\n",
    "        matrix containing pairwise inner products (d=1)\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    base_kernel(X1, X2):\n",
    "        evaluate the pairwise inner products (d=1) between {X1} and {X2}\n",
    "    kernel(hparam, row_indices, col_indices):\n",
    "        evaluate the polynomial kernel of degree {d} by raising the\n",
    "        {base_kernel_matrix} to power {d}\n",
    "    '''\n",
    "\n",
    "    def __init__(self, X1, X2=None):\n",
    "        super().__init__(X1, X2)\n",
    "\n",
    "    def base_kernel(self, X1, X2):\n",
    "\n",
    "        '''\n",
    "        Evaluate the pairwise inner products (d=1) between {X1} and {X2}\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X1: np.ndarray\n",
    "            first data matrix of shape (N, D)\n",
    "        X2: np.ndarray\n",
    "            second data matrix of shape (M, D)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        dot_products: np.ndarray\n",
    "            kernel matrix of shape (N, M) containing pariwise inner products\n",
    "        '''\n",
    "        \n",
    "        # evaluate the {base_kernel_matrix} as pairwise inner products\n",
    "        dot_products = X1 @ X2.T\n",
    "\n",
    "        return dot_products\n",
    "    \n",
    "    def kernel(self, hparam, row_indices=None, col_indices=None):\n",
    "\n",
    "        '''\n",
    "        Check the indices requested from {X1} and {X2} respectively, and\n",
    "        format them to be a valid index for the {base_kernel_matrix}\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        hparam: int\n",
    "            degree of the polynomial kernel\n",
    "        row_indices: np.ndarray\n",
    "            sequence of N indices requested from {X1}\n",
    "        col_indices: np.ndarray\n",
    "            sequence of M indices requested from {X2}\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        kernel_matrix: np.ndarray\n",
    "            kernel matrix of shape ({len(row_indices)}, {len(col_indices)})\n",
    "            evaluated using the polynomial kernel of degree {hparam}\n",
    "        '''\n",
    "\n",
    "        # get a valid index for the {base_kernel_matrix}\n",
    "        indices = self.indices(row_indices, col_indices)\n",
    "        # evaluate the kernel matrix as the d-th power of the inner products\n",
    "        kernel_matrix = np.power(self.base_kernel_matrix[indices], hparam)\n",
    "\n",
    "        return kernel_matrix\n",
    "    \n",
    "full_kernel = PolynomialKernel(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_coefs(n_classifiers, train_size):\n",
    "\n",
    "    '''\n",
    "    Initialize the multi-class perceptron coefficients as 0s. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    n_classifiers: int\n",
    "        number of classifiers -- 10 for OvA and 45 for OvO\n",
    "    train_size: int\n",
    "        number of training points\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    coefs: np.ndarray\n",
    "        0 initialized array of shape ({n_classifiers}, {train_size})\n",
    "        containing the coefficients of the kernel perceptrons\n",
    "    '''\n",
    "    \n",
    "    coefs = np.zeros((n_classifiers, train_size))\n",
    "    return coefs\n",
    "    \n",
    "def predict(coefs, kernel_values):\n",
    "\n",
    "    '''\n",
    "    Predict the pre-activation output for given classifiers at given \n",
    "    test points. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    coefs: np.ndarray\n",
    "        2-D array containing the coefficients of the classifiers\n",
    "        we want predictions for\n",
    "    kernel_values: np.ndarray\n",
    "        2-D array containing the kernel evaluations between the test\n",
    "        points and the training points\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    predictions: np.ndarray\n",
    "        output of the affine map, computed before applying the \n",
    "        Heaviside non-linearity\n",
    "    '''\n",
    "\n",
    "    predictions = coefs @ kernel_values.T\n",
    "    return predictions\n",
    "\n",
    "def sign(x):\n",
    "\n",
    "    '''\n",
    "    Compute the sign function evaluation for the entries in the input.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x: np.ndarray\n",
    "        n-D input array \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    signs: np.ndarray\n",
    "        sign function output for the array entries\n",
    "    '''\n",
    "\n",
    "    return np.where(x <= 0., -1., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_kernel, train_y, coefs, n_epochs=1):\n",
    "\n",
    "    '''\n",
    "    Train the k-class kernel perceptron using One-vs-All generalization.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_kernel: np.ndarray\n",
    "        pairwise kernel evaluations for the training points\n",
    "    train_y: np.ndarray\n",
    "        labels for the training set\n",
    "    coefs: np.ndarray\n",
    "        k-class kernel perceptron coefficients\n",
    "    n_epochs: int\n",
    "        number of epochs to train the classifier for\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coefs: np.ndarray\n",
    "        updated coefficients of the k-class kernel perceptron\n",
    "    mistakes: List[int]\n",
    "        mistakes made on the training set in each epoch\n",
    "    '''\n",
    "    \n",
    "    # keep track of the mistakes made on the training set in each epoch\n",
    "    mistakes = [0 for _ in range(n_epochs)]\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(train_y.size):\n",
    "            # retrieve the kernel evaluations between the new training point and the old ones\n",
    "            features, y = train_kernel[i], train_y[i]\n",
    "            # predict the pre-activation outputs and the class prediction\n",
    "            predictions = predict(coefs, features); argmax = np.argmax(predictions)\n",
    "            # if the prediction doesn't match the label, increment the number of mistakes\n",
    "            if argmax != y:\n",
    "                mistakes[epoch] += 1\n",
    "            # set the label for the classifier corresponding to the class {y} as 1 and -1 for the rest \n",
    "            labels = np.full(coefs.shape[0], -1.); labels[int(y)] = 1.\n",
    "            # update the coefficients for the classifiers which made a mistake\n",
    "            updates = np.where(labels*predictions <= 0., sign(predictions), 0.)\n",
    "            coefs[:, i] -= updates\n",
    "\n",
    "    return coefs, mistakes\n",
    "\n",
    "def test(test_kernel, test_y, coefs, return_cm=False):\n",
    "\n",
    "    '''\n",
    "    Test the k-class perceptron using One-vs-All generalization.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    test_kernel: np.ndarray\n",
    "        pairwise kernel evaluations for the test points with training points\n",
    "    train_y: np.ndarray\n",
    "        labels for the testing set\n",
    "    coefs: np.ndarray\n",
    "        k-class kernel perceptron coefficients\n",
    "    return_cm: bool\n",
    "        Boolean value indicating whether to return the confusion matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mistakes: int\n",
    "        mistakes made on the testing set\n",
    "    confusion_matrix: np.ndarray (returned only if {return_cm} is True)\n",
    "        confusion matrix with labels indexed as rows and predictions as columns\n",
    "    '''\n",
    "\n",
    "    # make the pre-activation predictions on the test set\n",
    "    predictions = predict(coefs, test_kernel)\n",
    "    # compute the class prediction as the argmax of outputs of the classifiers \n",
    "    argmax = np.argmax(predictions, axis=0)\n",
    "    # compute mistakes as the number of incorrectly predicted labels\n",
    "    mistakes = np.sum(argmax != test_y)\n",
    "    yield mistakes\n",
    "\n",
    "    # compute and yield the confusion matrix if {return_cm} is True\n",
    "    if return_cm:\n",
    "        confusion_matrix = np.zeros((N_CLASSES, N_CLASSES))\n",
    "        np.add.at(confusion_matrix, (test_y.astype(int), argmax), 1.)\n",
    "        yield confusion_matrix\n",
    "    else:\n",
    "        yield None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_run(train_x, train_y, test_x, test_y, d, n_classes, n_epochs):\n",
    "\n",
    "    '''\n",
    "    Demo run with a subset of data corresponding to the classes 1-3.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_x: np.ndarray\n",
    "        training data inputs with features along the rows\n",
    "    train_y: np.ndarray\n",
    "        training data labels\n",
    "    test_x: np.ndarray\n",
    "        testing data inputs with features along the rows\n",
    "    test_y: np.ndarray\n",
    "        testing data labels\n",
    "    d: int\n",
    "        polynomial kernel dimension\n",
    "    n_classes: int\n",
    "        number of classes in the demo dataset\n",
    "    n_epochs: int\n",
    "        number of epochs to train the classifier for\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coefs: np.ndarray\n",
    "        {n_classes}-class kernel perceptron coefficients\n",
    "    '''\n",
    "\n",
    "    # compute kernel matrix for the training set using a polynomial kernel of degree d\n",
    "    train_kernel = PolynomialKernel(train_x).kernel(d)\n",
    "    # compute kernel matrix for the testing set using a polynomial kernel of degree d\n",
    "    test_kernel = PolynomialKernel(test_x, train_x).kernel(d)\n",
    "    # initialize the coefficients for the {n_classes}-class kernel perceptron\n",
    "    coefs = init_coefs(n_classes, train_x.shape[0])\n",
    "    \n",
    "    for i in range(1, n_epochs+1):\n",
    "        # train the perceptron for one epoch\n",
    "        coefs, train_mistakes = train(train_kernel, train_y, coefs, n_epochs=1)\n",
    "        # test it using the updated coefficients after {i} epochs\n",
    "        test_mistakes, _ = test(test_kernel, test_y, coefs, return_cm=False)\n",
    "        # log the results on the training and the testing sets\n",
    "        print(f'Epoch {i} - {train_mistakes[-1]} mistakes out of {train_x.shape[0]} items on training set, test error is {test_mistakes/test_x.shape[0]*100:.3f}%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - 15 mistakes out of 329 items on training set, test error is 3.509%.\n",
      "Epoch 2 - 3 mistakes out of 329 items on training set, test error is 2.851%.\n",
      "Epoch 3 - 0 mistakes out of 329 items on training set, test error is 2.632%.\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = import_data('dtrain123.dat')\n",
    "test_x, test_y = import_data('dtest123.dat')\n",
    "\n",
    "execute_run(train_x, train_y-1, test_x, test_y-1, d=3, n_classes=3, n_epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-vs-All generalization of a perceptron to k-classes\n",
    "n_classifiers = N_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_1(n_runs, hparams, n_epochs):\n",
    "\n",
    "    '''\n",
    "    Perform k-class kernel perceptron training for different values of hyper-parameter choice.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_runs: int\n",
    "        number of runs to perform with each hyper-parameter choice\n",
    "    hparams: Iterable\n",
    "        a sequence of hyper-parameter choices\n",
    "    n_epochs: int\n",
    "        number of epochs to train the perceptron for in each run\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    error_rates: Dict\n",
    "        dictionary pointing to mean and standard deviation of error rates over {n_runs} runs\n",
    "        computed for each choice of the hyper-parameter\n",
    "    '''\n",
    "\n",
    "    # store results on the training and the test sets\n",
    "    # {value[run, i]} records the number of mistakes in {run}-th run using hyper-parameter {hparams[i]} \n",
    "    error_rates = {'train': np.zeros((n_runs, len(hparams))), 'test': np.zeros((n_runs, len(hparams)))}\n",
    "\n",
    "    for i in range(len(hparams)):\n",
    "\n",
    "        # extract the hyper-parameter value\n",
    "        hparam = hparams[i]\n",
    "        # compute the kernel matrix from the {base_kernel_matrix} using the hyper-parameter value\n",
    "        full_kernel_h = full_kernel.kernel(hparam)\n",
    "\n",
    "        for run in range(n_runs):\n",
    "\n",
    "            # make a 80-20 train-test split\n",
    "            train_indices, test_indices = train_test_split(np.arange(X.shape[0]), train_size=0.8, shuffle=True)\n",
    "            # extract the features for the training and the testing sets\n",
    "            train_kernel, test_kernel = full_kernel_h[np.ix_(train_indices, train_indices)], full_kernel_h[np.ix_(test_indices, train_indices)]\n",
    "            # extract the labels for the training and the testing sets\n",
    "            train_y, test_y = Y[train_indices], Y[test_indices]\n",
    "\n",
    "            # initialize the coefficients\n",
    "            coefs = init_coefs(n_classifiers, train_indices.size)\n",
    "            # train the generalized kernel perceptron for {n_epochs}\n",
    "            coefs, train_mistakes = train(train_kernel, train_y, coefs, n_epochs=n_epochs)\n",
    "            # test the learnt generalized kernel perceptron\n",
    "            test_mistakes, _ = test(test_kernel, test_y, coefs, return_cm=False)\n",
    "            \n",
    "            # update logs\n",
    "            error_rates['train'][run, i] = train_mistakes[-1]/train_y.size\n",
    "            error_rates['test'][run, i] = test_mistakes/test_y.size\n",
    "\n",
    "    # calculate the mean and standard deviation of the error rates on training and testing sets\n",
    "    error_rates['train'] = [f'{100*m:.3f} ± {100*s:.3f}' for m, s in zip(np.mean(error_rates['train'], axis=0), np.std(error_rates['train'], axis=0))]\n",
    "    error_rates['test']  = [f'{100*m:.3f} ± {100*s:.3f}' for m, s in zip(np.mean(error_rates['test'], axis=0),  np.std(error_rates['test'], axis=0))]\n",
    "\n",
    "    return error_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m N_RUNS, N_EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m      2\u001b[0m D \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m error_rates \u001b[38;5;241m=\u001b[39m \u001b[43mquestion_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_runs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_RUNS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_EPOCHS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39merror_rates\u001b[38;5;241m.\u001b[39mvalues()), index\u001b[38;5;241m=\u001b[39mD, columns\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain error (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest error (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDegree\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 31\u001b[0m, in \u001b[0;36mquestion_1\u001b[1;34m(n_runs, hparams, n_epochs)\u001b[0m\n\u001b[0;32m     29\u001b[0m hparam \u001b[38;5;241m=\u001b[39m hparams[i]\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# compute the kernel matrix from the {base_kernel_matrix} using the hyper-parameter value\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m full_kernel_h \u001b[38;5;241m=\u001b[39m \u001b[43mfull_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m run \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_runs):\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# make a 80-20 train-test split\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     train_indices, test_indices \u001b[38;5;241m=\u001b[39m train_test_split(np\u001b[38;5;241m.\u001b[39marange(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), train_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.8\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[4], line 72\u001b[0m, in \u001b[0;36mPolynomialKernel.kernel\u001b[1;34m(self, hparam, row_indices, col_indices)\u001b[0m\n\u001b[0;32m     70\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices(row_indices, col_indices)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# evaluate the kernel matrix as the d-th power of the inner products\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m kernel_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_kernel_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kernel_matrix\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_RUNS, N_EPOCHS = 20, 3\n",
    "D = range(1, 8)\n",
    "error_rates = question_1(n_runs=N_RUNS, hparams=D, n_epochs=N_EPOCHS)\n",
    "\n",
    "df = pd.DataFrame(data=zip(*error_rates.values()), index=D, columns=('Train error (%)', 'Test error (%)'))\n",
    "df.index = df.index.rename('Degree')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_2(n_runs, n_splits, hparams, n_epochs, return_cm=True):\n",
    "\n",
    "    '''\n",
    "    Find the sample statistics of the estimate for best hyper-parameter choice by performing \n",
    "    k-class kernel perceptron training with different values of hyper-parameter choice.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_runs: int\n",
    "        number of runs to perform with each hyper-parameter choice\n",
    "    n_splits: int\n",
    "        number of splits used for cross-validation\n",
    "    hparams: Iterable\n",
    "        a sequence of hyper-parameter choices\n",
    "    n_epochs: int\n",
    "        number of epochs to train the perceptron for in each run\n",
    "    return_cm: bool\n",
    "        Boolean value indicating whether to return the confusion matrix\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results: Dict\n",
    "        - results['hparam_star'] is an array storing the best hyper-parameter from each run \n",
    "        found using cross-validation\n",
    "        - results['test_error'] is an array storing the test error for the classifier trained\n",
    "        with the best hyper-parameter from each run\n",
    "    confusion_matrix: np.ndarray (returned only if {return_cm} is True)\n",
    "        confusion matrix with labels indexed as rows and predictions as columns\n",
    "    '''\n",
    "\n",
    "    # 5-fold splitter for cross-validation\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "    # confusion matrix for each run\n",
    "    confusion_matrix = [None for _ in range(n_runs)]\n",
    "    # best hyper-parameter found in each run using cross-validation and the corresponding test error \n",
    "    results = {'hparam_star': np.zeros((n_runs,)), 'test_error': np.zeros((n_runs,))}\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        \n",
    "        # split the data indices into train and test sets\n",
    "        train_indices, test_indices = train_test_split(np.arange(X.shape[0]), train_size=0.8, shuffle=True)\n",
    "        \n",
    "        # initialize an array for storing the validation errors corresponding to each hyper-parameter choice\n",
    "        val_errors = np.zeros((len(hparams), n_splits))\n",
    "        for i, hparam in enumerate(hparams):\n",
    "            # compute the full kernel matrix corresponding to the hyper-parameter choice\n",
    "            full_kernel_h = full_kernel.kernel(hparam)\n",
    "            for fold, (train_fold, val_fold) in enumerate(kfold.split(train_indices)):\n",
    "                # extract the features for the training and the validation sets\n",
    "                train_kernel, val_kernel = full_kernel_h[np.ix_(train_fold, train_fold)], full_kernel_h[np.ix_(val_fold, train_fold)]\n",
    "                # extract the labels for the training and the validation sets\n",
    "                train_y, val_y = Y[train_fold], Y[val_fold]\n",
    "                # initialize the coefficients\n",
    "                coefs = init_coefs(n_classifiers, train_fold.size)\n",
    "                # train the generalized kernel perceptron for {n_epochs}\n",
    "                coefs, _ = train(train_kernel, train_y, coefs, n_epochs=n_epochs)\n",
    "                # validate the learnt generalized kernel perceptron\n",
    "                val_mistakes, _ = test(val_kernel, val_y, coefs, return_cm=False)\n",
    "                val_errors[i, fold] = val_mistakes/val_y.size\n",
    "        \n",
    "        # take the mean of the validation errors on the {n_splits} folds\n",
    "        val_errors = val_errors.mean(axis=1)\n",
    "        # compute the best hyper-parameter as the one with the minimum mean validation error\n",
    "        hparam_star = hparams[np.argmin(val_errors)]; results['hparam_star'][run] = hparam_star\n",
    "\n",
    "        # recompute the kernel matrix using the best hyper-parameter \n",
    "        full_kernel_h = full_kernel.kernel(hparam_star)\n",
    "        # extract the features for the training and the testing sets\n",
    "        train_kernel, test_kernel = full_kernel_h[np.ix_(train_indices, train_indices)], full_kernel_h[np.ix_(test_indices, train_indices)]\n",
    "        # extract the labels for the training and the testing sets\n",
    "        train_y, test_y = Y[train_indices], Y[test_indices]\n",
    "        # initialize the coefficients\n",
    "        coefs = init_coefs(n_classifiers, train_indices.size)\n",
    "        # train the generalized kernel perceptron for {n_epochs}\n",
    "        coefs, _ = train(train_kernel, train_y, coefs, n_epochs=n_epochs)\n",
    "        # test the learnt generalized kernel perceptron\n",
    "        test_mistakes, confusion_matrix[run] = test(test_kernel, test_y, coefs, return_cm=return_cm)\n",
    "        results['test_error'][run] = test_mistakes/test_y.size\n",
    "\n",
    "    yield results\n",
    "    if return_cm:\n",
    "        yield np.stack(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "results, confusion_matrix = question_2(n_runs=N_RUNS, n_splits=N_SPLITS, hparams=D, n_epochs=N_EPOCHS, return_cm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "AxesImage.set() got an unexpected keyword argument 'fraction'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m fig, axs \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m7\u001b[39m))\n\u001b[0;32m     10\u001b[0m axs\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredictions\u001b[39m\u001b[38;5;124m'\u001b[39m, font\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserif\u001b[39m\u001b[38;5;124m'\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m); axs\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabels\u001b[39m\u001b[38;5;124m'\u001b[39m, font\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mserif\u001b[39m\u001b[38;5;124m'\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m im, cbar \u001b[38;5;241m=\u001b[39m \u001b[43mheatmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcm_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBlues\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbarlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTest Errors (\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.046\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m texts \u001b[38;5;241m=\u001b[39m annotate_heatmap(im, labels\u001b[38;5;241m=\u001b[39mlabels)\n\u001b[0;32m     13\u001b[0m fig\u001b[38;5;241m.\u001b[39mtight_layout()\n",
      "File \u001b[1;32mc:\\Users\\Jasraj\\Desktop\\UCL\\Supervised Learning\\Assignment 2\\plots.py:36\u001b[0m, in \u001b[0;36mheatmap\u001b[1;34m(data, row_labels, col_labels, ax, cbar_kw, cbarlabel, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m     cbar_kw \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Plot the heatmap\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m im \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mimshow(data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Create colorbar\u001b[39;00m\n\u001b[0;32m     39\u001b[0m cbar \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mcolorbar(im, ax\u001b[38;5;241m=\u001b[39max, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcbar_kw)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\__init__.py:1473\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1472\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1473\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1475\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1476\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1477\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\axes\\_axes.py:5656\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5654\u001b[0m     aspect \u001b[38;5;241m=\u001b[39m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage.aspect\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m   5655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m-> 5656\u001b[0m im \u001b[38;5;241m=\u001b[39m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAxesImage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5657\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5658\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5659\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5660\u001b[0m \u001b[43m                      \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5661\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5663\u001b[0m im\u001b[38;5;241m.\u001b[39mset_data(X)\n\u001b[0;32m   5664\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\_api\\deprecation.py:454\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    449\u001b[0m     warn_deprecated(\n\u001b[0;32m    450\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    453\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\image.py:922\u001b[0m, in \u001b[0;36mAxesImage.__init__\u001b[1;34m(self, ax, cmap, norm, interpolation, origin, extent, filternorm, filterrad, resample, interpolation_stage, **kwargs)\u001b[0m\n\u001b[0;32m    905\u001b[0m \u001b[38;5;129m@_api\u001b[39m\u001b[38;5;241m.\u001b[39mmake_keyword_only(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.6\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcmap\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, ax,\n\u001b[0;32m    907\u001b[0m              cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    917\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    918\u001b[0m              ):\n\u001b[0;32m    920\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extent \u001b[38;5;241m=\u001b[39m extent\n\u001b[1;32m--> 922\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    931\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\image.py:274\u001b[0m, in \u001b[0;36m_ImageBase.__init__\u001b[1;34m(self, ax, cmap, norm, interpolation, origin, filternorm, filterrad, resample, interpolation_stage, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m ax\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_imcache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\artist.py:1223\u001b[0m, in \u001b[0;36mArtist._internal_update\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_internal_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, kwargs):\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1218\u001b[0m \u001b[38;5;124;03m    Update artist properties without prenormalizing them, but generating\u001b[39;00m\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;124;03m    errors as if calling `set`.\u001b[39;00m\n\u001b[0;32m   1220\u001b[0m \n\u001b[0;32m   1221\u001b[0m \u001b[38;5;124;03m    The lack of prenormalization is to maintain backcompatibility.\u001b[39;00m\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_props\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{cls.__name__}\u001b[39;49;00m\u001b[38;5;124;43m.set() got an unexpected keyword argument \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{prop_name!r}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\matplotlib\\artist.py:1197\u001b[0m, in \u001b[0;36mArtist._update_props\u001b[1;34m(self, props, errfmt)\u001b[0m\n\u001b[0;32m   1195\u001b[0m             func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   1196\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[1;32m-> 1197\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m   1198\u001b[0m                     errfmt\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m), prop_name\u001b[38;5;241m=\u001b[39mk))\n\u001b[0;32m   1199\u001b[0m             ret\u001b[38;5;241m.\u001b[39mappend(func(v))\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret:\n",
      "\u001b[1;31mAttributeError\u001b[0m: AxesImage.set() got an unexpected keyword argument 'fraction'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"d* = {np.mean(results['hparam_star']):.3f} ± {np.std(results['hparam_star']):.3f}\")\n",
    "print(f\"Test error (%) = {100*np.mean(results['test_error']):.3f} ± {100*np.std(results['test_error']):.3f}\")\n",
    "\n",
    "confusion_matrix = confusion_matrix / confusion_matrix.sum(axis=2, keepdims=True)\n",
    "cm_mean = np.mean(confusion_matrix, axis=0); np.fill_diagonal(cm_mean, 0.)\n",
    "cm_std = np.std(confusion_matrix, axis=0)\n",
    "labels = np.array([f'{100*mean:.1f} ±\\n{100*std:.1f}' for mean, std in zip(cm_mean.flatten(), cm_std.flatten())]).reshape(cm_mean.shape); np.fill_diagonal(labels, '')\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(7, 7))\n",
    "axs.set_xlabel('Predictions', font='serif', size=12); axs.set_title('Labels', font='serif', size=12)\n",
    "im, cbar = heatmap(100*cm_mean, np.arange(10), np.arange(10), cmap='Blues', cbarlabel='Test Errors (%)', ax=axs)\n",
    "texts = annotate_heatmap(im, labels=labels)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hardest_samples(kernel, ys, coefs, n=5):\n",
    "\n",
    "    '''\n",
    "    Find the hardest samples to predict as the ones with the lowest pre-activation\n",
    "    prediction given by the classifier corresponding to the class given by their label.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    kernel: np.ndarray\n",
    "        kernel matrix of the particular dataset we are finding the hardest samples from\n",
    "    ys: np.ndarray\n",
    "        labels for the dataset we are finding the hardest samples from\n",
    "    coefs: np.ndarray\n",
    "        k-class kernel perceptron coefficients\n",
    "    n: int\n",
    "        number of hardest samples to return\n",
    "\n",
    "    Returs\n",
    "    ------\n",
    "    hardest_samples: np.ndarray\n",
    "        indices of the {n} hardest samples from the given dataset\n",
    "    '''\n",
    "\n",
    "    predictions = predict(coefs, kernel)\n",
    "    labels = np.full(predictions.shape, -1.); labels[ys.astype(int), np.arange(predictions.shape[1])] = 1.\n",
    "    best_pred = np.max(labels*predictions, axis=0)\n",
    "    hardest_samples = np.argpartition(best_pred, n)[:n]\n",
    "    \n",
    "    return hardest_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(img, label, fn=None, show=False):\n",
    "    \n",
    "    fig, axs = plt.subplots(figsize=(4, 4))\n",
    "    img = img.reshape(16, 16)\n",
    "    axs.imshow(img, cmap='viridis', interpolation='none')\n",
    "    axs.set_title(f'Label = {label}', fontdict={'font': 'serif', 'size': 16})\n",
    "    axs.get_xaxis().set_visible(False); axs.get_yaxis().set_visible(False)\n",
    "    fig.tight_layout()\n",
    "    if fn is not None:\n",
    "        fig.savefig(fn)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = np.round(np.mean(results['hparam_star']))\n",
    "full_kernel_d = full_kernel.kernel(d)\n",
    "\n",
    "train_indices, test_indices = train_test_split(np.arange(X.shape[0]), train_size=0.8, shuffle=True)\n",
    "train_kernel, test_kernel = full_kernel_d[np.ix_(train_indices, train_indices)], full_kernel_d[np.ix_(test_indices, train_indices)]\n",
    "train_y, test_y = Y[train_indices], Y[test_indices]\n",
    "\n",
    "coefs = init_coefs(n_classifiers, train_indices.size)\n",
    "coefs, train_mistakes = train(train_kernel, train_y, coefs, n_epochs=N_EPOCHS)\n",
    "indices = hardest_samples(test_kernel, test_y, coefs, n=5)\n",
    "hardest_test_samples = test_indices[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display = 1\n",
    "\n",
    "dirpath = Path('assets')\n",
    "if dirpath.exists() and dirpath.is_dir():\n",
    "    shutil.rmtree(dirpath)\n",
    "dirpath.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for index in hardest_test_samples:\n",
    "    img, label = X[index], int(Y[index])\n",
    "    plot(img, label, fn=f'{dirpath}/sample-{index}_label-{label}.png', show=False)\n",
    "\n",
    "index = hardest_test_samples[display-1]\n",
    "img, label = X[index], int(Y[index])\n",
    "plot(img, label, fn=None, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianKernel(PolynomialKernel):\n",
    "\n",
    "    '''\n",
    "    Compute the Gaussian kernel with width c by first precomputing the \n",
    "    kernel matrix with c=1, and then raising it to the power c.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    base_kernel_matrix: np.ndarray\n",
    "        matrix containing pairwise Gaussian kernel evaluations for c=1\n",
    "    \n",
    "    Methods\n",
    "    -------\n",
    "    base_kernel(X1, X2):\n",
    "        evaluate the kernel matrix between points in {X1} and {X2} with c=1\n",
    "    '''\n",
    "\n",
    "    def __init__(self, X1, X2=None):\n",
    "        super().__init__(X1, X2)\n",
    "\n",
    "    def base_kernel(self, X1, X2):\n",
    "\n",
    "        '''\n",
    "        Evaluate the width 1 Gaussian kernel matrix between {X1} and {X2}\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X1: np.ndarray\n",
    "            first data matrix of shape (N, D)\n",
    "        X2: np.ndarray\n",
    "            second data matrix of shape (M, D)\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        squared_exp_kernel: np.ndarray\n",
    "            kernel matrix of shape (N, M) containing pairwise Gaussian kernel\n",
    "            evaluations with c=1\n",
    "        '''\n",
    "        \n",
    "        # evaluate the pairwise squared L2-distances\n",
    "        squared_distances = np.sum(np.square(X1), axis=1, keepdims=True) + \\\n",
    "            np.sum(np.square(X2).T, axis=0, keepdims=True) - \\\n",
    "            2 * X1 @ X2.T\n",
    "        # evaluate the {base_kernel_matrix} using Gaussian kernel of width 1 \n",
    "        squared_exp_kernel = np.exp(-squared_distances)\n",
    "        \n",
    "        return squared_exp_kernel\n",
    "    \n",
    "full_kernel = GaussianKernel(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train error (%)</th>\n",
       "      <th>Test error (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Width</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>0.371 ± 0.053</td>\n",
       "      <td>3.062 ± 0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.015</th>\n",
       "      <td>0.196 ± 0.039</td>\n",
       "      <td>2.836 ± 0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.020</th>\n",
       "      <td>0.137 ± 0.027</td>\n",
       "      <td>2.742 ± 0.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.025</th>\n",
       "      <td>0.161 ± 0.047</td>\n",
       "      <td>2.710 ± 0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.030</th>\n",
       "      <td>0.160 ± 0.038</td>\n",
       "      <td>2.812 ± 0.399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.035</th>\n",
       "      <td>0.175 ± 0.057</td>\n",
       "      <td>3.108 ± 0.409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.040</th>\n",
       "      <td>0.184 ± 0.044</td>\n",
       "      <td>3.315 ± 0.349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train error (%) Test error (%)\n",
       "Width                               \n",
       "0.010   0.371 ± 0.053  3.062 ± 0.393\n",
       "0.015   0.196 ± 0.039  2.836 ± 0.800\n",
       "0.020   0.137 ± 0.027  2.742 ± 0.213\n",
       "0.025   0.161 ± 0.047  2.710 ± 0.313\n",
       "0.030   0.160 ± 0.038  2.812 ± 0.399\n",
       "0.035   0.175 ± 0.057  3.108 ± 0.409\n",
       "0.040   0.184 ± 0.044  3.315 ± 0.349"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = np.linspace(0.01, 0.04, num=7, endpoint=True)\n",
    "error_rates = question_1(n_runs=N_RUNS, hparams=C, n_epochs=N_EPOCHS)\n",
    "\n",
    "df = pd.DataFrame(data=zip(*error_rates.values()), index=np.round(C, 3), columns=('Train error (%)', 'Test error (%)'))\n",
    "df.index = df.index.rename('Width')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c* = 0.020 ± 0.005\n",
      "Test error (%) = 2.790 ± 0.509\n"
     ]
    }
   ],
   "source": [
    "results, = question_2(n_runs=N_RUNS, n_splits=N_SPLITS, hparams=C, n_epochs=N_EPOCHS, return_cm=False)\n",
    "\n",
    "print(f\"c* = {np.mean(results['hparam_star']):.3f} ± {np.std(results['hparam_star']):.3f}\")\n",
    "print(f\"Test error (%) = {100*np.mean(results['test_error']):.3f} ± {100*np.std(results['test_error']):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_combinations = [(0, 1), (0, 2), ..., (0, 9), (1, 2), ..., (1, 9), ..., (7, 8), (7, 9), (8, 9)]\n",
    "#     => if the prediction of classifier {k} is {y'} = 0/1, then the class voted for is class_combinations[k][y']\n",
    "# classifier_mapping = [[0, 1, ..., 8], [0, 9, 10, ..., 16], ..., [8, 16, 23, 29, 34, 38, 41, 43, 44]]\n",
    "#     => classifier_mapping[y] is a list of indices, [k], such that classifier {k} compares class {y} with another class\n",
    "#     used for accessing the classifiers that need to be updated after seeing the training point (x, y)\n",
    "\n",
    "class_combinations, k = list(), -1\n",
    "classifier_mapping = [[] for _ in range(N_CLASSES)]\n",
    "\n",
    "for class_a in range(N_CLASSES):\n",
    "    for k, class_b in enumerate(range(class_a+1, N_CLASSES), k+1):\n",
    "        class_combinations.append((class_a, class_b))\n",
    "        classifier_mapping[class_a].append(k); classifier_mapping[class_b].append(k)\n",
    "\n",
    "class_combinations = np.array(class_combinations)\n",
    "n_classifiers = k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_kernel, train_y, coefs, n_epochs=1):\n",
    "\n",
    "    '''\n",
    "    Train the k-class kernel perceptron using One-vs-One generalization.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    train_kernel: np.ndarray\n",
    "        pairwise kernel evaluations for the training points\n",
    "    train_y: np.ndarray\n",
    "        labels for the training set\n",
    "    coefs: np.ndarray\n",
    "        k-class kernel perceptron coefficients\n",
    "    n_epochs: int\n",
    "        number of epochs to train the classifier for\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coefs: np.ndarray\n",
    "        updated coefficients of the k-class kernel perceptron\n",
    "    mistakes: List[int]\n",
    "        mistakes made on the training set in each epoch\n",
    "    '''\n",
    "\n",
    "    # keep track of the mistakes made on the training set in each epoch\n",
    "    mistakes = [0 for _ in range(n_epochs)]\n",
    "    for epoch in range(n_epochs):\n",
    "        for i in range(train_y.size):\n",
    "            # retrieve the kernel evaluations between the new training point and the old ones\n",
    "            features, y = train_kernel[i], train_y[i]\n",
    "            # predict the pre-activation outputs and the class prediction\n",
    "            predictions = predict(coefs, features)\n",
    "            # aggregate the votes from each of the classifiers\n",
    "            votes = class_combinations[np.arange(n_classifiers), (predictions>0.).astype(int)]\n",
    "            # use hard voting to compute the majority vote\n",
    "            vote_counts = np.bincount(votes); hard_mx = np.argmax(vote_counts)\n",
    "            # if the prediction doesn't match the label, increment the number of mistakes\n",
    "            if hard_mx != y:\n",
    "                mistakes[epoch] += 1\n",
    "            # extract the classifiers relevant to the data sample (ones that involve label {y})\n",
    "            classifiers = classifier_mapping[int(y)]\n",
    "            # extract the predictions from the relevant classifiers\n",
    "            predictions = predictions[classifiers]\n",
    "            # set the label for the classifiers comparing label {y} against another label y' \n",
    "            # as 1 and the labels for the rest of the classifiers as -1 \n",
    "            labels = np.full(len(classifiers), -1.); labels[:int(y)] = 1.\n",
    "            # update the coefficients for the classifiers which made a mistake\n",
    "            updates = np.where(labels*predictions <= 0., sign(predictions), 0.)\n",
    "            coefs[classifiers, i] -= updates\n",
    "\n",
    "    return coefs, mistakes\n",
    "\n",
    "def test(test_kernel, test_y, coefs, return_cm=False):\n",
    "\n",
    "    '''\n",
    "    Test the k-class perceptron using One-vs-One generalization.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    test_kernel: np.ndarray\n",
    "        pairwise kernel evaluations for the test points with training points\n",
    "    train_y: np.ndarray\n",
    "        labels for the testing set\n",
    "    coefs: np.ndarray\n",
    "        k-class kernel perceptron coefficients\n",
    "    return_cm: bool\n",
    "        Boolean value indicating whether to return the confusion matrix\n",
    "        (not used, only here for consistency)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mistakes: int\n",
    "        mistakes made on the testing set\n",
    "    '''\n",
    "\n",
    "    # make the pre-activation predictions on the test set\n",
    "    predictions = predict(coefs, test_kernel)\n",
    "    # extract the votes given by each classifier\n",
    "    row_indices = np.tile(np.arange(predictions.shape[0]), (predictions.shape[1], 1)).T\n",
    "    votes = class_combinations[row_indices, (predictions>0.).astype(int)]\n",
    "    # make a counter for the votes given to each class\n",
    "    vote_counts = np.apply_along_axis(lambda x: np.bincount(x, minlength=N_CLASSES), axis=0, arr=votes)\n",
    "    # find the majority vote for each test point\n",
    "    hard_mxs = np.argmax(vote_counts, axis=0)\n",
    "    # compute mistakes as the number of incorrectly predicted labels\n",
    "    mistakes = np.sum(hard_mxs != test_y)\n",
    "    \n",
    "    return mistakes, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_kernel = PolynomialKernel(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train error (%)</th>\n",
       "      <th>Test error (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Degree</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.264 ± 0.225</td>\n",
       "      <td>7.134 ± 0.699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.350 ± 0.181</td>\n",
       "      <td>4.355 ± 0.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.405 ± 0.169</td>\n",
       "      <td>3.696 ± 0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.055 ± 0.106</td>\n",
       "      <td>3.804 ± 0.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.866 ± 0.114</td>\n",
       "      <td>3.640 ± 0.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.809 ± 0.103</td>\n",
       "      <td>3.610 ± 0.479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.729 ± 0.119</td>\n",
       "      <td>3.672 ± 0.394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Train error (%) Test error (%)\n",
       "Degree                               \n",
       "1        6.264 ± 0.225  7.134 ± 0.699\n",
       "2        2.350 ± 0.181  4.355 ± 0.486\n",
       "3        1.405 ± 0.169  3.696 ± 0.462\n",
       "4        1.055 ± 0.106  3.804 ± 0.387\n",
       "5        0.866 ± 0.114  3.640 ± 0.379\n",
       "6        0.809 ± 0.103  3.610 ± 0.479\n",
       "7        0.729 ± 0.119  3.672 ± 0.394"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rates = question_1(n_runs=N_RUNS, hparams=D, n_epochs=N_EPOCHS)\n",
    "\n",
    "df = pd.DataFrame(data=zip(*error_rates.values()), index=D, columns=('Train error (%)', 'Test error (%)'))\n",
    "df.index = df.index.rename('Degree')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d* = 4.950 ± 1.203\n",
      "Test error (%) = 3.675 ± 0.446\n"
     ]
    }
   ],
   "source": [
    "results, = question_2(n_runs=N_RUNS, n_splits=N_SPLITS, hparams=D, n_epochs=N_EPOCHS, return_cm=False)\n",
    "\n",
    "print(f\"d* = {np.mean(results['hparam_star']):.3f} ± {np.std(results['hparam_star']):.3f}\")\n",
    "print(f\"Test error (%) = {100*np.mean(results['test_error']):.3f} ± {100*np.std(results['test_error']):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_kernel = GaussianKernel(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train error (%)</th>\n",
       "      <th>Test error (%)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Width</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.010</th>\n",
       "      <td>1.144 ± 0.148</td>\n",
       "      <td>3.685 ± 0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.015</th>\n",
       "      <td>0.838 ± 0.096</td>\n",
       "      <td>3.328 ± 0.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.020</th>\n",
       "      <td>0.739 ± 0.098</td>\n",
       "      <td>3.505 ± 0.601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.025</th>\n",
       "      <td>0.657 ± 0.106</td>\n",
       "      <td>3.599 ± 0.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.030</th>\n",
       "      <td>0.573 ± 0.105</td>\n",
       "      <td>3.788 ± 0.457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.035</th>\n",
       "      <td>0.544 ± 0.098</td>\n",
       "      <td>3.710 ± 0.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.040</th>\n",
       "      <td>0.465 ± 0.074</td>\n",
       "      <td>3.954 ± 0.372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Train error (%) Test error (%)\n",
       "Width                               \n",
       "0.010   1.144 ± 0.148  3.685 ± 0.625\n",
       "0.015   0.838 ± 0.096  3.328 ± 0.456\n",
       "0.020   0.739 ± 0.098  3.505 ± 0.601\n",
       "0.025   0.657 ± 0.106  3.599 ± 0.520\n",
       "0.030   0.573 ± 0.105  3.788 ± 0.457\n",
       "0.035   0.544 ± 0.098  3.710 ± 0.524\n",
       "0.040   0.465 ± 0.074  3.954 ± 0.372"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_rates = question_1(n_runs=N_RUNS, hparams=C, n_epochs=N_EPOCHS)\n",
    "\n",
    "df = pd.DataFrame(data=zip(*error_rates.values()), index=C, columns=('Train error (%)', 'Test error (%)'))\n",
    "df.index = df.index.rename('Width')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results, \u001b[38;5;241m=\u001b[39m question_2(n_runs\u001b[38;5;241m=\u001b[39mN_RUNS, n_splits\u001b[38;5;241m=\u001b[39mN_SPLITS, hparams\u001b[38;5;241m=\u001b[39mC, n_epochs\u001b[38;5;241m=\u001b[39mN_EPOCHS, return_cm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc* = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhparam_star\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhparam_star\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest error (%) = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mmean(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_error\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mstd(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_error\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 48\u001b[0m, in \u001b[0;36mquestion_2\u001b[1;34m(n_runs, n_splits, hparams, n_epochs, return_cm)\u001b[0m\n\u001b[0;32m     45\u001b[0m val_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(hparams), n_splits))\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, hparam \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(hparams):\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m# compute the full kernel matrix corresponding to the hyper-parameter choice\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m     full_kernel_h \u001b[38;5;241m=\u001b[39m \u001b[43mfull_kernel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_fold, val_fold) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kfold\u001b[38;5;241m.\u001b[39msplit(train_indices)):\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;66;03m# extract the features for the training and the validation sets\u001b[39;00m\n\u001b[0;32m     51\u001b[0m         train_kernel, val_kernel \u001b[38;5;241m=\u001b[39m full_kernel_h[np\u001b[38;5;241m.\u001b[39mix_(train_fold, train_fold)], full_kernel_h[np\u001b[38;5;241m.\u001b[39mix_(val_fold, train_fold)]\n",
      "Cell \u001b[1;32mIn[4], line 72\u001b[0m, in \u001b[0;36mPolynomialKernel.kernel\u001b[1;34m(self, hparam, row_indices, col_indices)\u001b[0m\n\u001b[0;32m     70\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices(row_indices, col_indices)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# evaluate the kernel matrix as the d-th power of the inner products\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m kernel_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpower\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_kernel_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m kernel_matrix\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results, = question_2(n_runs=N_RUNS, n_splits=N_SPLITS, hparams=C, n_epochs=N_EPOCHS, return_cm=False)\n",
    "\n",
    "print(f\"c* = {np.mean(results['hparam_star']):.3f} ± {np.std(results['hparam_star']):.3f}\")\n",
    "print(f\"Test error (%) = {100*np.mean(results['test_error']):.3f} ± {100*np.std(results['test_error']):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
